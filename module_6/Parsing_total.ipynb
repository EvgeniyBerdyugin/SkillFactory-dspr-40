{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9c81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd  \n",
    "import requests\n",
    "from pprint import pprint\n",
    "from ast import literal_eval\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc5171",
   "metadata": {},
   "source": [
    "Создаем список марок, интересующих нас, как они обозначены на сайте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bfc7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['audi', 'bmw', 'honda', 'infiniti', 'lexus', 'mercedes', 'mitsubishi', 'nissan', 'skoda', 'toyota', 'volkswagen', 'volvo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_of_cars(url):\n",
    "    \n",
    "    '''функция считает количество объявлений по ссылке'''\n",
    "    \n",
    "    req = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    req.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    count = soup.find('span', class_=\"ButtonWithLoader__content\")\n",
    "    pattern = re.compile('\\d')\n",
    "    number = ''\n",
    "    for i in pattern.findall(count.text):\n",
    "        number += i\n",
    "    \n",
    "    return int(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cars_on_parts(url_base):\n",
    "    \n",
    "    '''функция разделяет каждую марку по году производства, так что бы\n",
    "    уложится в максимальное количество объявлений выводимых по запросу'''\n",
    "    \n",
    "    num_of_cars = count_of_cars(url_base)\n",
    "    num_of_parts = int(num_of_cars / 3000) + 1\n",
    "    url_list = []\n",
    "\n",
    "    if num_of_cars <= 3670:\n",
    "        print(url_base)\n",
    "        url_list.append(url_base)\n",
    "    else:\n",
    "        year1 = 2016\n",
    "        url = url_base + '?year_to=' + str(year1)\n",
    "        if num_of_parts == 2:\n",
    "            while count_of_cars(url) not in range(2900,3600):\n",
    "                url = url_base + '?year_to=' + str(year1)\n",
    "                year1 -= 1\n",
    "                time.sleep(0.3)\n",
    "            url2 = url_base + '?year_from=' + str(year1 + 2)\n",
    "            print(url)\n",
    "            url_list.append(url)\n",
    "            print(url2)\n",
    "            url_list.append(url2)\n",
    "        elif num_of_parts > 2:\n",
    "            while count_of_cars(url) not in range(2900,3600):\n",
    "                year1 -= 1\n",
    "                url = url_base + '?year_to=' + str(year1)\n",
    "                time.sleep(0.3)\n",
    "            print(url)\n",
    "            url_list.append(url)\n",
    "            year1 += 1\n",
    "            year2 = year1 + 1\n",
    "            for i in range(num_of_parts - 2):\n",
    "                url = url_base + '?year_from=' + str(year1) + '&year_to=' + str(year2)\n",
    "                while count_of_cars(url) not in range(2900,3600):\n",
    "                    year2 += 1\n",
    "                    url = url_base + '?year_from=' + str(year1) + '&year_to=' + str(year2)\n",
    "                    time.sleep(0.3)\n",
    "                print(url)\n",
    "                url_list.append(url)\n",
    "                year1, year2 = year2, year2 + 2\n",
    "            print(url_base + '?year_from=' + str(year2))\n",
    "            url_list.append(url_base + '?year_from=' + str(year2))\n",
    "    \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f61f6b",
   "metadata": {},
   "source": [
    "Адрес, на котором объявления о продаже авто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c783782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "domen = 'https://auto.ru/cars/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598c4232",
   "metadata": {},
   "source": [
    "Создаем список адресов, по интересующим нас маркам, разделенные по году производства, так, что бы уложиться в максимальное число выводимых объявлений. По запросу максимум выдает 99 страниц, из них первые 7 по 38 объявлений, остальные  по 37, итого не более 3670 объявления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56158e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_list:\n",
    "    url_base = domen + model + '/used/'\n",
    "    req = requests.get(url_base, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    req.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(req.text, 'html.parser')\n",
    "    car_url_list += split_cars_on_parts(url_base)\n",
    "df = pd.DataFrame(car_url_list, columns=['url'])\n",
    "df.to_csv('links.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927910e",
   "metadata": {},
   "source": [
    "Сохраняем результат в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6753745",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c9476",
   "metadata": {},
   "source": [
    "Проходим по каждой ссылке и сохраняем адрем каждого объявления в один список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf02bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_list = []\n",
    "df = pd.DataFrame(cars_list, columns=['url'])\n",
    "for url in urls.url:\n",
    "    num_of_cars = count_of_cars(url)\n",
    "    num_of_sheets = (num_of_cars - 266) // 37 + 8\n",
    "    for i in range(num_of_sheets):\n",
    "        links = ''\n",
    "        params = {'page': i+1}\n",
    "        req = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, params=params)\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        links = soup.find_all('a', class_=\"Link ListingItemTitle__link\")\n",
    "        cars = len(links)\n",
    "        #time.sleep(0.4)\n",
    "        for link in range(cars):\n",
    "            cars_list.append(links[link]['href'])\n",
    "            print(links[link]['href'])\n",
    "            print(len(cars_list))\n",
    "            df = pd.DataFrame(cars_list, columns=['url'])\n",
    "            df.to_csv('cars_Total.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a51850",
   "metadata": {},
   "source": [
    "Проходим по всему списку объявлений и копируем всю интересующую нас техническую информацию и каждую строчку записываем в файл, так как занимает очень много времени и возможны различные сбои, а так же меньше загружает память."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9925c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = open('total_car_info.csv', 'w', encoding=\"utf-8\")\n",
    "csv_writer = csv.writer(cars)\n",
    "csv_writer.writerow(['car_url', 'info1', 'info2', \n",
    "                     'info2owner', 'info2Card', 'info3', \n",
    "                     'info4', 'comp_link', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbaed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('cars_Total.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3f4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in links.url:\n",
    "    try:\n",
    "        req = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        req.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        dff1 = pd.DataFrame(index=[0], columns=['car_url', 'info1', 'info2', 'info2owner', 'info2Card', 'info3', 'info4', 'comp_link', 'time'])\n",
    "        car_url = url\n",
    "        info_1 = soup.find_all('script', type=\"application/ld+json\")\n",
    "        info1 = literal_eval(str(info_1[0]).strip('<script type=\"application/ld+json\"> </script>'))\n",
    "        info_2 = soup.find_all('div', class_=\"CardOfferBody__leftColumn\")\n",
    "        info2 = soup.find_all('div', class_=\"CardOfferBody__leftColumn\")\n",
    "        info2owner = info_2[0].find_all('div', class_=\"CardBenefits__item-title\")\n",
    "        info2Card = info_2[0].find_all('span', class_=\"CardInfoRow__cell\")\n",
    "        info3 = soup.find_all('section', class_=\"CardComplectation CardOfferBody__contentIsland\")\n",
    "        info_4 = soup.find_all('div', id=\"sale-data-attributes\")\n",
    "        info4 = literal_eval(str(info_4[0]).strip('<div data-bem=' 'id=\"sale-data-attributes\" style=\"display:none\"></div>'))\n",
    "        comp_link_1 = soup.find_all('a', class_=\"Link SpoilerLink CardCatalogLink SpoilerLink_type_default\")\n",
    "        comp_link = comp_link_1[0]['href']\n",
    "        time = datetime.today()\n",
    "        print(links[links['url'] == url].index)\n",
    "        csv_writer.writerow(\n",
    "                [car_url, info1, info2, \n",
    "                     info2owner, info2Card, info3, \n",
    "                     info4, comp_link, time])\n",
    "    except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893eef4b",
   "metadata": {},
   "source": [
    "По каждому объявлению мы сохранили ссылку на описание комплектации, они повторяются. Создадим список уникальных ссылок и скачаем информацию из них. А так как в тестовых данных нет этой ссылки, добавим общую информацию по каждому такому авто, что бы потом найти соотвествие для тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2200bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\negat\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('total_car_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfdb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complect = pd.DataFrame()\n",
    "columns = ['comp_link', 'engineDisplacement', 'enginePower', 'model_name', 'vehicleConfiguration', 'vehicleTransmission']\n",
    "data_complect['comp_link'] = dataset.comp_link.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complect['engineDisplacement'] = None\n",
    "data_complect['enginePower'] = None\n",
    "data_complect['model_name'] = None\n",
    "data_complect['vehicleConfiguration'] = None\n",
    "data_complect['vehicleTransmission'] = None\n",
    "for i in range(len(data_complect)):\n",
    "    data_complect['engineDisplacement'][i] = dataset.engineDisplacement[dataset.comp_link == data_complect.comp_link[i]].iloc[0]\n",
    "    data_complect['enginePower'][i] = dataset.enginePower[dataset.comp_link == data_complect.comp_link[i]].iloc[0]\n",
    "    data_complect['model_name'][i] = dataset.model_name[dataset.comp_link == data_complect.comp_link[i]].iloc[0]\n",
    "    data_complect['vehicleConfiguration'][i] = dataset.vehicleConfiguration[dataset.comp_link == data_complect.comp_link[i]].iloc[0]\n",
    "    data_complect['vehicleTransmission'][i] = dataset.vehicleTransmission[dataset.comp_link == data_complect.comp_link[i]].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedc787",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complect.to_csv('comp_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde27a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('comp_links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a72931e",
   "metadata": {},
   "source": [
    "Скачиваем информацию по комплектациям и записываем в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comp_dict'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c55f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    try:\n",
    "        req2 = requests.get(data.comp_link[i], headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        req2.encoding = 'utf-8'\n",
    "        soup2 = BeautifulSoup(req2.text, 'html.parser')\n",
    "\n",
    "        dd = soup2.find_all('dd', class_=\"list-values__value\")\n",
    "\n",
    "        dt = soup2.find_all('dt', class_=\"list-values__label\")\n",
    "\n",
    "        dic = {}\n",
    "\n",
    "\n",
    "        for (part, name) in zip(dt, dd):\n",
    "            dic.setdefault(part.text, name.text)\n",
    "        data['comp_dict'][i] = dic\n",
    "        print(i)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f589eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('comp_links_dicts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
